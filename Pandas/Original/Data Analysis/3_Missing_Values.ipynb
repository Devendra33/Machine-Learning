{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Missing_Values.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "swdzqGYYA5CC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Handling Missing values of file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ds = pd.read_csv(\"Data.csv\")\n",
        "# fillna()\n",
        "\n",
        "ds.fillna(0)  # fill nan values with zero in all columns\n",
        "ds.fillna({\"Age\": 0,\n",
        "           \"Salary\":\"not known\" })  # to fill missing values accoriding to columns\n",
        "ds.fillna(method  = \"ffill\", limit = 1)    # forward fill, copy only 1 time\n",
        "ds.fillna(method = \"bfill\", limit = 2)     # backword fill, copy 2 times\n",
        "\n",
        "# to fill nan with intermeadiate value of adjacent upper and lower cell \n",
        "ds.interpolate(method = \"time\")\n",
        "\n",
        "# dropna()\n",
        "\n",
        "ds.dropna()   # default how = any, drops every row which has nan value in any column\n",
        "ds.dropna(how = \"all\")    # drops a rows when all columns are nan only\n",
        "\n",
        "# Now thresh param, drop a row with valid(not null) numbers of values\n",
        "# if thresh = 1, then atleast one not value should be present\n",
        "ds.dropna(thresh = 3) # does not drop any.\n",
        "ds.dropna(thresh = 4) # means requires 4 valid values, so drop rows with null value \n",
        "\n",
        "# Handling missing values using replace function.\n",
        "\n",
        "dic = {\"Temperature\": [-32,-99999,28,-99999,32,31,34], \"Windspeed\": [6,7,-99999,8,-88888,2,8], \"Event\":[\"rain\",\"sunny\",\"no event\",\"rain\",\"no event\",\"sunny\",\"sunny\"]}\n",
        "df = pd.DataFrame(dic)\n",
        "\n",
        "df.replace(-99999, np.nan)  # replaces all -99999 by Nan in whole df\n",
        "df.replace([-99999, -88888], np.nan) # used for replacing multiple values\n",
        "\n",
        "df.replace({\"Temperature\" : -99999,   # for replacing values according to the columns.\n",
        "            \"Windspeed\" : -88888,   # for changing -99999 we can pass list of values as well\n",
        "            \"Event\" : \"no event\"\n",
        "        }, np.nan)\n",
        "\n",
        "df.replace({-99999:np.nan,    # when just simply wants to replace this values from whole table \n",
        "            -88888:np.nan, \n",
        "            \"no event\": \"snow\"})\n",
        "\n",
        "dic1 = {\"Temperature\": [\"-32 f\",-99999,28,-99999,\"32 f\",31,34], \"Windspeed\": [\"6 mph\",7,-99999 ,\"8 mph\",-88888,2,8], \"Event\":[\"rain\",\"sunny\",\"no event\",\"rain\",\"no event\",\"sunny\",\"sunny\"]}\n",
        "df1 = pd.DataFrame(dic1)\n",
        "\n",
        "# tough task .....using regex\n",
        "df1.replace(\"[A-Za-z]\", \"\", regex = True) # replace all alphabetss with blancks\n",
        "\n",
        "df1.replace({\"Temperature\": \"[A-Za-z]\",   # replace all alphabetss with blancks according to a columns\n",
        "             \"Windspeed\": \"[A-Za-z]\"}, \"\", regex = True)\n",
        "\n",
        "# Now replacing a list by list\n",
        "dic2 = {\"score\": [\"good\", \"poor\", \"excellent\", \"average\", \"good\", \"good\",\"poor\"], \"names\":[\"dex\",\"aman\",\"aru\",\"kabir\",\"ragju\",\"ran\",\"sxx\"]}\n",
        "df2 = pd.DataFrame(dic2)\n",
        "\n",
        "df2.replace([\"good\", \"poor\", \"excellent\", \"average\"], [2,0,4,3])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}