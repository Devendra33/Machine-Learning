{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_Evaluate.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dK2DtquFp3-1","colab_type":"code","colab":{}},"source":["# projects that gives the best linear model suitable for data set.\n","# works only when the data set is preprocessed.\n","# the dependent variable must be at the end.\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PolynomialFeatures\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVR\n","from sklearn.metrics import r2_score\n","import statsmodels.api as sm\n","\n","# preprcess dataset here.\n","\n","# preprocess ends here....\n","\n","# Read preprocessed file here.\n"," \n","ds = pd.read_csv(\"pre_beaver.csv\")\n","\n","x = ds.iloc[:,:-1].values\n","y = ds.iloc[:,-1].values\n","\n","x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 0)\n","\n","def bestlinearmodel(x_train, x_test, y_train, y_test):\n","    # Linear Regression ::   lin_reg.predict() (Model)\n","    dic = {}\n","    if len(x_train[0:1].ravel()) == 1:\n","        \n","        lin_reg = LinearRegression()\n","        lin_reg.fit(x_train, y_train)\n","        lin_pred = lin_reg.predict(x_test)\n","        dic[\"Simple_Linear_Regression: \"] = r2_score(y_test, lin_pred)\n","    \n","    # Multiple Linear Regression :: mul_reg.predict()     (Model)\n","    \n","    mul_reg = LinearRegression()\n","    mul_reg.fit(x_train, y_train)\n","    mul_pred = mul_reg.predict(x_test)\n","    dic[\"Multiple_Linear_Regression: \"] = r2_score(y_test, mul_pred)\n","    \n","    # Polynomial linear regression :: pol_reg.predict()    (Model)\n","    poly_reg = PolynomialFeatures(degree = 3)\n","    x_poly = poly_reg.fit_transform(x_train)\n","    pol_reg = LinearRegression()\n","    pol_reg.fit(x_poly, y_train)\n","    pol_pred = pol_reg.predict(poly_reg.fit_transform(x_test))\n","    dic[\"Polynomial_Linear_Regression: \"] = r2_score(y_test, pol_pred)\n","    \n","    # Decision tree Regression::dec_reg                            (Model)\n","    \n","    dec_reg = DecisionTreeRegressor(random_state = 0)\n","    dec_reg.fit(x_train, y_train)\n","    dec_pred = dec_reg.predict(x_test)\n","    dic[\"Decision_Tree_Regression: \"] = r2_score(y_test, dec_pred)\n","    \n","    # Random forest Regression                             (Model)\n","    ran_reg = RandomForestRegressor(n_estimators = 10, random_state = 0)\n","    ran_reg.fit(x_train, y_train)\n","    ran_pred = ran_reg.predict(x_test)    \n","    dic[\"Random_Forest_Regression: \"] = r2_score(y_test, ran_pred)\n","    \n","    # Support Vector Regression :: svr_reg.predict()          (Model)\n","    # performing feature scaling.    \n","    dec = 0\n","    if min(y_train) >= 0 and max(y) <= 3:\n","        sc_x = StandardScaler()\n","        x_train = sc_x.fit_transform(x_train)\n","        x_test = sc_x.transform(x_test)\n","        dec = 1\n","    else:\n","        y_test = y_test.reshape(len(y_test),1)\n","        y_train = y_train.reshape(len(y_train),1)\n","        sc_x = StandardScaler()\n","        sc_y = StandardScaler()\n","        x_train = sc_x.fit_transform(x_train)\n","        x_test = sc_x.transform(x_test)\n","        y_train = sc_y.fit_transform(y_train)\n","        y_test = sc_y.transform(y_test)\n","        \n","    svr_reg = SVR(kernel = \"rbf\")\n","    svr_reg.fit(x_train, y_train)\n","    \n","    if dec == 1:\n","        y_pred = svr_reg.predict(x_test)\n","        dic[\"Support_Vector_Regression: \"] = r2_score(y_test, y_pred)   # yeh y me values normal hai\n","    else:\n","        y_pred = sc_y.inverse_transform(svr_reg.predict(x_test))\n","        dic[\"Support_Vector_Regression: \"] = r2_score(sc_y.inverse_transform(y_test), y_pred)  # isme values inverse krna padega\n","    \n","    return dic\n","    \n","d = bestlinearmodel(x_train, x_test, y_train, y_test)\n","m = max(d.values())\n","for k, v in d.items():\n","    print(k, v)\n","    if m == v:\n","        model = k\n","        mv = v\n","print(end = \"\\n\\n\\n\")\n","if len(x_train[0:1].ravel()) == 1:\n","    %matplotlib inline\n","    plt.scatter(x_train, y_train, color = \"red\")\n","    #plt.plot(x_train, lin_reg.predict(x_train), color = \"blue\") # to see only scattering\n","    plt.title(\"Graph\")\n","    plt.xlabel(\"x-axis\")\n","    plt.ylabel(\"y-axis\")\n","    plt.show()\n","        \n","print(\"The best Model is:\\n      \", model, mv)\n","print(end = \"\\n\\n\\n\\n\")"],"execution_count":0,"outputs":[]}]}