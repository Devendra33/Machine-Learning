{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultipleLinearRegression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dK2DtquFp3-1","colab_type":"code","colab":{}},"source":["# Multiple Linear Regression\n","# important methods\n","# backward elimination  \n","# forward selection \n","# bi-direction elimination\n","# we do not need to perform feature scaling.\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","# importing the dataset\n","ds = pd.read_csv(\"50_Startups.csv\")\n","\n","x = ds.iloc[:,0:4].values\n","y = ds.iloc[:,4].values\n"," \n","lab_x = LabelEncoder()\n","x[:,3] = lab_x.fit_transform(x[:,3])\n","ohe = OneHotEncoder(categorical_features = [3])\n","x = ohe.fit_transform(x).toarray()\n","\n","# taking care of dummy variable trap\n","x = x[:,1:]        # for some softwares it is nesscary to do this but librabry takes care of it in this course\n","\n","# spliting the data into train and test dataset\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/5, random_state = 0)\n","\n","# Fitting the training data into regressor.\n","regressor = LinearRegression()\n","regressor.fit(x_train, y_train)\n","\n","# predicting the value\n","y_pred = regressor.predict(x_test)\n","\n","#  now to perform backward elimination we add 1 in front of dataset(x), bcoz, y = b0 + b1x1 + b2x2+...+bnxn.\n","x = np.append(arr = np.ones((50,1)).astype(int), values = x, axis = 1)\n","\n","# performing the backword elimination method.\n","import statsmodels.api as sm\n"," # SL = 0.5   (Significance Level)\n","x_opt = x[:,[0,1,2,3,4,5]]\n","regress_OLS = sm.OLS(endog = y, exog = x_opt).fit()   #endog = dependent , exog = optimal matrix.\n","regress_OLS.summary()      # remove 1 bcoz of highest significance value\n","x_opt = x[:,[0,2,3,4,5]]\n","regress_OLS = sm.OLS(endog = y, exog =x_opt).fit()\n","regress_OLS.summary()  # remove 2 \n","x_opt = x[:,[0,3,4,5]]\n","regress_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regress_OLS.summary()  # remove 4\n","x_opt = x[:,[0,3,5]]\n","regress_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regress_OLS.summary()  # remove 5\n","x_opt = x[:,[0,3]]\n","regress_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n","regress_OLS.summary()\n","\n"],"execution_count":0,"outputs":[]}]}